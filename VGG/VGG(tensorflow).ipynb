{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9db3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'truncated_normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1./ 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'function'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def VGG(feature, im_height=224, im_weight=224, num_classes=1000):\n",
    "    input_image = layers.Input(shape=(im_height, im_weight, 3), dtype=\"float32\")\n",
    "    x = feature(input_image)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(rate = 0.5)(x)\n",
    "    x = layers.Dense(2048, activation='relu',\n",
    "                     kernel_initializer = DENSE_KERNEL_INITIALIZER)(x)\n",
    "    x = layers.Dropout(rate = 0.5)(x)\n",
    "    x = layers.Dense(2048, activation='relu',\n",
    "                     kernel_initializer = DENSE_KERNEL_INITIALIZER)(x)\n",
    "    x = layers.Dense(num_classes, \n",
    "                     kernel_initializer = DENSE_KERNEL_INITIALIZER)(x)\n",
    "    output = layers.Softmax()(x)\n",
    "    model = Model(inputs = input_image, outputs = output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_features(cfg):\n",
    "    feature_layers = []\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            feature_layers.append(layers.MaxPool2D(pool_size=2, strides=2))\n",
    "        else:\n",
    "            conv2d = layers.Conv2d(v, kernel_size =3, padding = \"SAME\", activation=\"relu\",\n",
    "                                   kernel_initializer = CONV_KERNEL_INITIALIZER)\n",
    "            feature_layers.appenda(conv2d)\n",
    "    return Sequential(feature_layers, name = \"features\")\n",
    "\n",
    "\n",
    "def vgg(model_name=\"vgg16\", im_height=224, im_width=224, num_classes=1000):\n",
    "    assert model_name in cfgs.keys(), \"not support model {}\".format(model_name)\n",
    "    cfg = cfgs[model_name]\n",
    "    model = VGG(make_feature(cfg), im_height=im_height, im_width=im_width, num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07111c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "image_path = os.path.join(data_root, \"input/flowerdata\", \"flower_data\")\n",
    "\n",
    "train_dir = os.path.join(image_path, \"train\")\n",
    "validation_dir = os.path.join(image_path, \"val\")\n",
    "assert os.path.exists(train_dir), \"cannot find {}\".format(train_dir)\n",
    "assert os.path.exists(validation_dir), \"cannot find {}\".format(validation_dir)\n",
    "\n",
    "if not os.path.exists(\"save_weights\"):\n",
    "    os.makedirs(\"save_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height = 224\n",
    "im_width = 224\n",
    "batch_size = 32\n",
    "epoch = 10\n",
    "\n",
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d53bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_function(img):\n",
    "    img = img - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(horizontal_flip=True,\n",
    "                                           preprocessing_function=pre_function\n",
    ")\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(preprocessing_function=pre_function)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                           batch_size=batch_size,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size = (im_height, im_height),\n",
    "                                                           class_mode='categorical')\n",
    "total_train = train_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b300b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(directory = validation_dir,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              shuffle=False,\n",
    "                                                              target_size = (im_height, im_width),\n",
    "                                                              class_mode='categorical'\n",
    "                                                             )\n",
    "\n",
    "total_val = val_data_gen.n\n",
    "pring(\"using {} images for training, {} images for validation.\".format(total_train, total_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_data_gen.class_indices\n",
    "\n",
    "inverse_dict = dict((val, key) for key, val in class_indices.items())\n",
    "\n",
    "json_str = json.dumps(inverse_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(\"vgg16\", 224, 224, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015047f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_weights_path = './pretrain_weights.ckpt'\n",
    "assert len(glob.glob(pre_weights_path+\"*\")), \"cannot find {}\".format(pre_weights_path)\n",
    "model.load_weights(pre_weights_path)\n",
    "for layer_t in model.layers:\n",
    "    if layer_t.name = 'feature':\n",
    "        layer_t.trainable = False\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./save_weights/myAlex_{epoch}.h5',\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = train_data_gen,\n",
    "                    steps_per_epoch = total_train // batch_size,\n",
    "                    epoch = epochs,\n",
    "                    validation_data = val_data_gen,\n",
    "                    validation_steps = total_val // batch_size,\n",
    "                    callbacks = callbacks\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4491bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
