{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4d3682",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4997ec95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = \"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_writer = tf.summary.create_file_writer(os.path.join())\n",
    "val_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"val\"))\n",
    "\n",
    "\n",
    "#data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "data_root = './'\n",
    "image_path = os.path.join(data_root, \"flower_data\")\n",
    "train_dir = os.path.join(image_path, \"train\")\n",
    "validation_dir = os.path.join(image_path, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b70f0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class dict\n",
    "data_class = [cla for cla in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, cla))]\n",
    "class_num = len(data_class)\n",
    "class_dict = dict((value, index) for index, value in enumerate(data_class))\n",
    "\n",
    "# reverse value and key of dict\n",
    "inverse_dict = dict((val, key) for key, val in class_dict.items())\n",
    "# write dict into json file\n",
    "json_str = json.dumps(inverse_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "    \n",
    "# create direction for saving weights\n",
    "if not os.path.exists(\"save_weights\"):\n",
    "    os.makedirs(\"save_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246637f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im_height = 224\n",
    "im_width = 224\n",
    "\n",
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14044e83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m random\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m train_image_list \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[38;5;241m.\u001B[39mglob(train_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/*/*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m random\u001B[38;5;241m.\u001B[39mshuffle(train_image_list)\n\u001B[0;32m      5\u001B[0m train_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_image_list)\n",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m random\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m train_image_list \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[38;5;241m.\u001B[39mglob(train_dir \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/*/*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m random\u001B[38;5;241m.\u001B[39mshuffle(train_image_list)\n\u001B[0;32m      5\u001B[0m train_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_image_list)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PyCharm 2022.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharm 2022.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "train_image_path = glob.glob(train_dir + \"/*/*.jpg\")\n",
    "random.shuffle(train_image_path)\n",
    "train_num = len(train_image_path)\n",
    "train_label_list = [class_dict[path.split(os.path.sep)[-2]] for path in train_image_path]\n",
    "\n",
    "val_image_path = glob.glob(validation_dir + \"/*/*.jpg\")\n",
    "random.shuffle(val_image_path)\n",
    "val_num = len(val_image_path)\n",
    "val_label_list = [class_dict[path.split(os.path.sep)[-2]] for path in val_image_path]\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7e3ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_train_img(img_path, label):\n",
    "    label = tf.one_hot(label, depth=class_num)\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [im_height, im_width])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = image - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "    return image, label\n",
    "\n",
    "def process_val_img(img_path, label):\n",
    "    label = tf.one_hot(label, depth=class_num)\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [im_height, im_width])\n",
    "    image = image - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95c422",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((tf.constant(train_image_path),\n",
    "                                                    tf.constant(train_label_list)))\n",
    "total_train = len(train_image_path)\n",
    "\n",
    "train_dataset = train_dataset.map(process_train_img, num_parallel_calls=AUTOTUNE)\\\n",
    "                             .shuffle(buffer_size= total_train)\\\n",
    "                             .batch(batch_size)\\\n",
    "                             .prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((tf.constant(val_image_path),\n",
    "                                                  tf.constant(val_label_list)))\n",
    "total_val = len(val_image_path)\n",
    "val_dataset = val_dataset.map(process_train_img, num_parallel_calls=AUTOTUNE)\\\n",
    "                         .batch(batch_size)\\\n",
    "                         .prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5ae9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(layers.Layer):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, out_channel, stride = 1, downsample=None, **kwargs):\n",
    "        super(BasicBlock, self).__init__(**kwargs)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(out_channel, kernel_size=3, strides=strides,\n",
    "                                   padding=\"SAME\", use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization(momentum=0.9, epsilon=le-5)\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(out_channel, kernel_size=3, strides=1,\n",
    "                                    padding=\"SAME\", use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.relu = layers.ReLU()\n",
    "        self.add = layers.Add()\n",
    "        \n",
    "    def call(self, inputs, training = False):\n",
    "        identity = inputs\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs)\n",
    "            \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=tfraining)\n",
    "        \n",
    "        x = self.add([identity, x])\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Bottleneck(layers.Layer):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, out_channel, strides= 1, downsample=None, **kwargs):\n",
    "        super(Bottleneck, self).__init__(**kwargs)\n",
    "        self.conv1 = layers.Conv2D(out_channel, kernel_size=1, use_bias=False, name = \"conv1\")\n",
    "        self.bn1 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=\"conv1/BatchNorm\")\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(out_channel, kernel_size=3, use_bias=False,\n",
    "                                   strides=strides, padding=\"SAME\", name=\"conv2\")\n",
    "        self.bn2 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=\"conv2/BatchNorm\")\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(out_channel * self.expansion, kernel_size=1, use_bias=False, name=\"conv3\")\n",
    "        self.bn3 = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=\"conv3/BatchNorm\")\n",
    "        \n",
    "        self.relu = layers.ReLU()\n",
    "        self.downsample = downsample\n",
    "        self.add = layers.Add()\n",
    "       \n",
    "    \n",
    "    def call(self, inputs, training = False):\n",
    "        identity = inputs\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(inputs)\n",
    "            \n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training = training)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training = training)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x, training = training)\n",
    "        \n",
    "        x = self.add([x, identity])\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def _make_layer(block, in_channel, channel, block_num, name, strides=1):\n",
    "    downsample = None\n",
    "    if strides != 1 or in_channel != channel * block.expansion:\n",
    "        downsample = Sequential([\n",
    "            layers.Conv2D(channel * block.expansion, kernel_size=1, strides=strides,\n",
    "                          use_bias=False, name=\"conv1\"),\n",
    "            layers.BatchNormalization(momentum=0.9, epsilon=1.001e-5, name= \"BatchNorm\")\n",
    "        ], name=\"shortcut\")\n",
    "    \n",
    "    layers_list = []\n",
    "    layers_list.append(block(channel, downsample= downsample, strides=strides, name=\"unit_1\"))\n",
    "    \n",
    "    for index in range(1, block_num):\n",
    "        layers_list.append(block(channel, name=\"unit_\" + str(index + 1)))\n",
    "        \n",
    "    \n",
    "    return Sequential(layers_list, name=name)\n",
    "\n",
    "\n",
    "def _resnet(block, blocks_num, im_width = 224, im_height = 224, num_classes=1000, include_top=True):\n",
    "    input_image = layers.Input(shape=(im_height, im_width, 3), dtype=\"float32\")\n",
    "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2,\n",
    "                      padding=\"SAME\", use_bias=False, name=\"conv1\")(input_image)\n",
    "    \n",
    "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=\"conv1/BatchNorm\")(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding=\"SAME\")(x)\n",
    "    \n",
    "    x = _make_layer(block, x.shape[-1], 64, block_num=[0], name=\"block1\")(x)\n",
    "    x = _make_layer(block, x.shape[-1], 128, block_num=[1], strides= 2, name=\"block2\")(x)\n",
    "    x = _make_layer(block, x.shape[-1], 256, block_num=[2], strides= 2, name=\"block3\")(x)\n",
    "    x = _make_layer(block, x.shape[-1], 512, block_num=[3], strides= 2, name=\"block4\")(x)\n",
    "    \n",
    "    if include_top:\n",
    "        x = layers.GlobalAvgPool2D()(x)\n",
    "        x = layers.Dense(num_classes, name=\"logits\")(x)\n",
    "        predict = layers.Softmax()(x)\n",
    "    else:\n",
    "        predict = x\n",
    "\n",
    "    \n",
    "    model = Model(inputs=input_image, outputs = predict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def resnet34(im_width=224, im_height=224, num_classes=1000, include_top=True):\n",
    "    return _resnet(BasicBlock, [3, 4, 6, 3], im_width, im_height, num_classes, include_top)\n",
    "\n",
    "\n",
    "def resnet50(im_width=224, im_height=224, num_classes=1000, include_top=True):\n",
    "    return _resnet(Bottleneck, [3, 4, 6, 3], im_width, im_height, num_classes, include_top)\n",
    "\n",
    "\n",
    "def resnet101(im_width=224, im_height=224, num_classes=1000, include_top=True):\n",
    "    return _resnet(Bottleneck, [3, 4, 23, 3], im_width, im_height, num_classes, include_top)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78857d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature = resnet50(num_classes = 5, include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa6318",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pre_weights_path = './pretrain_weights.ckpt'\n",
    "feature.load_weights(pre_weights_path)\n",
    "feature.trainable =False\n",
    "feature.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3e8eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([feature,\n",
    "                             tf.keras.layers.GlobalAvgPool2D(),\n",
    "                             tf.keras.layers.Dropout(rate=0.5),\n",
    "                             tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "                             tf.keras.layers.Dropout(rate=0.5),\n",
    "                             tf.keras.layers.Dense(num_classes),\n",
    "                             tf.keras.layers.Softmax()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7a674",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a924c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " @tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = model(images, training=True)\n",
    "        loss = loss_object(labels, output)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, output)\n",
    "\n",
    "@tf.function\n",
    "def val_step(images, labels):\n",
    "    output = model(images, training=False)\n",
    "    loss = loss_object(labels, output)\n",
    "\n",
    "    val_loss(loss)\n",
    "    val_accuracy(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fcd30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " best_val_acc = 0.\n",
    "for epoch in range(epochs):\n",
    "    train_loss.reset_states()  # clear history info\n",
    "    train_accuracy.reset_states()  # clear history info\n",
    "    val_loss.reset_states()  # clear history info\n",
    "    val_accuracy.reset_states()  # clear history info\n",
    "\n",
    "    # train\n",
    "    train_bar = tqdm(train_dataset, file=sys.stdout)\n",
    "    for images, labels in train_bar:\n",
    "        train_step(images, labels)\n",
    "\n",
    "        # print train process\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}, acc:{:.3f}\".format(epoch + 1,\n",
    "                                                                                 epochs,\n",
    "                                                                                 train_loss.result(),\n",
    "                                                                                 train_accuracy.result())\n",
    "\n",
    "    optimizer.learning_rate = scheduler(epoch)\n",
    "\n",
    "    # validate\n",
    "    val_bar = tqdm(range(total_val // batch_size), file=sys.stdout)\n",
    "    for step in val_bar:\n",
    "        test_images, test_labels = next(val_data_gen)\n",
    "        val_step(test_images, test_labels)\n",
    "\n",
    "        # print val process\n",
    "        val_bar.desc = \"valid epoch[{}/{}] loss:{:.3f}, acc:{:.3f}\".format(epoch + 1,\n",
    "                                                                               epochs,\n",
    "                                                                               val_loss.result(),\n",
    "                                                                               val_accuracy.result())\n",
    "\n",
    "    # only save best weights\n",
    "    if val_accuracy.result() > best_val_acc:\n",
    "        best_val_acc = val_accuracy.result()\n",
    "        model.save_weights(\"./save_weights/resNet_50.ckpt\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b13fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_path = '../input/flower/flower.jpg'\n",
    "assert os.path.exists(image_path),\"file: '{}' dose not exist.\".format(image_path)\n",
    "img = Image.open(image_path)\n",
    "img = img.resize((im_width, im_height))\n",
    "plt.imshow(img)\n",
    "\n",
    "img = np.array(img).astype(np.float32)\n",
    "img = img - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "img = (np.expand_dims(img, 0))\n",
    "\n",
    "json_path = './class_indices.json'\n",
    "assert os.path.exists(json_path),\"file: '{}' does not exist.\".format(json_path)\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    class_indict = json.load(f)\n",
    "    \n",
    "feature = resnet50(num_classes = 5, include_top = False)\n",
    "feature.trainable = False\n",
    "# load weights\n",
    "weights_path = './save_weights/resNet_50.ckpt'\n",
    "assert len(glob.glob(weights_path+\"*\")), \"cannot find {}\".format(weights_path)\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "# prediction\n",
    "result = np.squeeze(model.predict(img))\n",
    "predict_class = np.argmax(result)\n",
    "\n",
    "print_res = \"class: {}   prob: {:.3}\".format(class_indict[str(predict_class)],\n",
    "                                             result[predict_class])\n",
    "plt.title(print_res)\n",
    "for i in range(len(result)):\n",
    "    print(\"class: {:10}   prob: {:.3}\".format(class_indict[str(i)],\n",
    "                                              result[i]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f343f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626233f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}