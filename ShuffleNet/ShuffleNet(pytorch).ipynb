{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from typing import List, Callable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m data_root \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(os\u001B[38;5;241m.\u001B[39mgetcwd(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../..\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m      2\u001B[0m image_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_root, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkaggle/input/flowerdata/\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflower_data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(image_path),\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile:\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(image_path)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "image_path = os.path.join(data_root, \"kaggle/input/flowerdata/\",\"flower_data\")\n",
    "assert os.path.exists(image_path),\"file:'{}' does not exist\".format(image_path)\n",
    "\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "epochs = 30\n",
    "\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
    "print('Using {} dataloader workers every process'.format(nw))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dir = os.path.join(image_path, \"train\")\n",
    "val_dir = os.path.join(image_path, \"val\")\n",
    "\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 225])]),\n",
    "    \"val\": transforms.Compose([transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, .224, 0.225])])\n",
    "}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transform['train'])\n",
    "validate_dataset = datasets.ImageFolder(val_dir, transform=data_transform['val'])\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "validate_num = len(validate_dataset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=nw,\n",
    "                                           pin_memory=True,\n",
    "                                           collate_fn=train_dataset.)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size = batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=nw,\n",
    "                                              pin_memory=True,\n",
    "                                              collate_fn=validate_dataset.vollate_fn)\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num, validate_num))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
    "flower_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "# write dict into json file\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def channel_shuffle(x: Tensor, groups: int) -> Tensor:\n",
    "\n",
    "    batch_size, num_channels, height, width = x.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    # [batch_size, num_channels, height, width] -> [batch_size, groups, channels_per_group, height, width]\n",
    "    x = x.view(batch_size, groups, channels_per_group, height, width)\n",
    "\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batch_size, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, input_c: int, output_c: int, stride: int):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "\n",
    "        if stride not in [1, 2]:\n",
    "            raise ValueError(\"illegal stride value.\")\n",
    "        self.stride = stride\n",
    "\n",
    "        assert output_c % 2 == 0\n",
    "        branch_features = output_c // 2\n",
    "        # 当stride为1时，input_channel应该是branch_features的两倍\n",
    "        # python中 '<<' 是位运算，可理解为计算×2的快速方法\n",
    "        assert (self.stride != 1) or (input_c == branch_features << 1)\n",
    "\n",
    "        if self.stride == 2:\n",
    "            self.branch1 = nn.Sequential(\n",
    "                self.depthwise_conv(input_c, input_c, kernel_s=3, stride=self.stride, padding=1),\n",
    "                nn.BatchNorm2d(input_c),\n",
    "                nn.Conv2d(input_c, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(branch_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.branch1 = nn.Sequential()\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(input_c if self.stride > 1 else branch_features, branch_features, kernel_size=1,\n",
    "                      stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            self.depthwise_conv(branch_features, branch_features, kernel_s=3, stride=self.stride, padding=1),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.Conv2d(branch_features, branch_features, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(branch_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def depthwise_conv(input_c: int,\n",
    "                       output_c: int,\n",
    "                       kernel_s: int,\n",
    "                       stride: int = 1,\n",
    "                       padding: int = 0,\n",
    "                       bias: bool = False) -> nn.Conv2d:\n",
    "        return nn.Conv2d(in_channels=input_c, out_channels=output_c, kernel_size=kernel_s,\n",
    "                         stride=stride, padding=padding, bias=bias, groups=input_c)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.stride == 1:\n",
    "            x1, x2 = x.chunk(2, dim=1)\n",
    "            out = torch.cat((x1, self.branch2(x2)), dim=1)\n",
    "        else:\n",
    "            out = torch.cat((self.branch1(x), self.branch2(x)), dim=1)\n",
    "\n",
    "        out = channel_shuffle(out, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 stages_repeats: List[int],\n",
    "                 stages_out_channels: List[int],\n",
    "                 num_classes: int = 1000,\n",
    "                 inverted_residual: Callable[..., nn.Module] = InvertedResidual):\n",
    "        super(ShuffleNetV2, self).__init__()\n",
    "\n",
    "        if len(stages_repeats) != 3:\n",
    "            raise ValueError(\"expected stages_repeats as list of 3 positive ints\")\n",
    "        if len(stages_out_channels) != 5:\n",
    "            raise ValueError(\"expected stages_out_channels as list of 5 positive ints\")\n",
    "        self._stage_out_channels = stages_out_channels\n",
    "\n",
    "        # input RGB image\n",
    "        input_channels = 3\n",
    "        output_channels = self._stage_out_channels[0]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        input_channels = output_channels\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Static annotations for mypy\n",
    "        self.stage2: nn.Sequential\n",
    "        self.stage3: nn.Sequential\n",
    "        self.stage4: nn.Sequential\n",
    "\n",
    "        stage_names = [\"stage{}\".format(i) for i in [2, 3, 4]]\n",
    "        for name, repeats, output_channels in zip(stage_names, stages_repeats,\n",
    "                                                  self._stage_out_channels[1:]):\n",
    "            seq = [inverted_residual(input_channels, output_channels, 2)]\n",
    "            for i in range(repeats - 1):\n",
    "                seq.append(inverted_residual(output_channels, output_channels, 1))\n",
    "            setattr(self, name, nn.Sequential(*seq))\n",
    "            input_channels = output_channels\n",
    "\n",
    "        output_channels = self._stage_out_channels[-1]\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(output_channels, num_classes)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.mean([2, 3])  # global pool\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def shufflenet_v2_x0_5(num_classes=1000):\n",
    "    \"\"\"\n",
    "    Constructs a ShuffleNetV2 with 0.5x output channels, as described in\n",
    "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
    "    <https://arxiv.org/abs/1807.11164>`.\n",
    "    weight: https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth\n",
    "    :param num_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = ShuffleNetV2(stages_repeats=[4, 8, 4],\n",
    "                         stages_out_channels=[24, 48, 96, 192, 1024],\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def shufflenet_v2_x1_0(num_classes=1000):\n",
    "    \"\"\"\n",
    "    Constructs a ShuffleNetV2 with 1.0x output channels, as described in\n",
    "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
    "    <https://arxiv.org/abs/1807.11164>`.\n",
    "    weight: https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\n",
    "    :param num_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = ShuffleNetV2(stages_repeats=[4, 8, 4],\n",
    "                         stages_out_channels=[24, 116, 232, 464, 1024],\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def shufflenet_v2_x1_5(num_classes=1000):\n",
    "    \"\"\"\n",
    "    Constructs a ShuffleNetV2 with 1.0x output channels, as described in\n",
    "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
    "    <https://arxiv.org/abs/1807.11164>`.\n",
    "    weight: https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth\n",
    "    :param num_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = ShuffleNetV2(stages_repeats=[4, 8, 4],\n",
    "                         stages_out_channels=[24, 176, 352, 704, 1024],\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def shufflenet_v2_x2_0(num_classes=1000):\n",
    "    \"\"\"\n",
    "    Constructs a ShuffleNetV2 with 1.0x output channels, as described in\n",
    "    `\"ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\"\n",
    "    <https://arxiv.org/abs/1807.11164>`.\n",
    "    weight: https://download.pytorch.org/models/shufflenetv2_x2_0-8be3c8ee.pth\n",
    "    :param num_classes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = ShuffleNetV2(stages_repeats=[4, 8, 4],\n",
    "                         stages_out_channels=[24, 244, 488, 976, 2048],\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = shufflenet_v2_x1_0(num_classes=5).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_weight_path = \"./resnet34-pre.pth\"\n",
    "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pg = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(pg, lr=0.01, momentum=0.9, weight_decay=4e-5)\n",
    "lrf = 0.1\n",
    "lf = lambda x: ((1 + math.cos(x * math.pi / epochs)) / 2)*(1 - lrf) + lrf\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    # train\n",
    "    mean_loss = train_one_epoch(model=model,\n",
    "                                optimizer=optimizer,\n",
    "                                data_loader=train_loader,\n",
    "                                device=device,\n",
    "                                epoch=epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # validate\n",
    "    acc = evaluate(model=model,\n",
    "                   data_loader=val_loader,\n",
    "                   device=device)\n",
    "\n",
    "    print(\"[epoch {}] accuracy: {}\".format(epoch, round(acc, 3)))\n",
    "    tags = [\"loss\", \"accuracy\", \"learning_rate\"]\n",
    "    tb_writer.add_scalar(tags[0], mean_loss, epoch)\n",
    "    tb_writer.add_scalar(tags[1], acc, epoch)\n",
    "    tb_writer.add_scalar(tags[2], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}